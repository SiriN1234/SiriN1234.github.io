<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>

    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>

    <!--Description-->

    

    
        <meta name="description" content="출처 : 혼자 공부하는 머신러닝+딥러닝
순차 데이터와 순환 신경망
초급 레벨 : 기초통계 (t.test, 분산분석, 회귀분석 등)
중급 레벨 : 시계열 분석 &amp;#x2F; 베이지안 &amp;#x2F; 비모수검정
시계열 데이터 : 주식 &amp;#x2F; 날씨 &amp;#x2F; 매장 매출
R"/>
    

    <!--Author-->
    
        <meta name="author" content="SiriN"/>
    

    <!--Open Graph Title-->
    
        <meta property="og:title" content="Chapter 8장"/>
    

    <!--Open Graph Description-->
    
        <meta property="og:description" content="출처 : 혼자 공부하는 머신러닝+딥러닝
순차 데이터와 순환 신경망
초급 레벨 : 기초통계 (t.test, 분산분석, 회귀분석 등)
중급 레벨 : 시계열 분석 &amp;#x2F; 베이지안 &amp;#x2F; 비모수검정
시계열 데이터 : 주식 &amp;#x2F; 날씨 &amp;#x2F; 매장 매출
R"/>
    

    <!--Open Graph Site Name-->
        <meta property="og:site_name" content="SiriN&#39;s Blog"/>

    <!--Type page-->
    
        <meta property="og:type" content="article"/>
    

    <!--Page Cover-->
    
    
        <meta property="og:image" content="https://SiriN1234.github.ioimg/home-bg.jpg"/>
    

        <meta name="twitter:card" content="summary_large_image"/>

    

    
        <meta name="twitter:image" content="https://SiriN1234.github.ioimg/home-bg.jpg"/>
    

    <!-- Title -->
    
    <title>Chapter 8장 - SiriN&#39;s Blog</title>

    <!-- Bootstrap Core CSS -->
    <link href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" rel="stylesheet"/>

    <!-- Custom CSS -->
    
<link rel="stylesheet" href="/css/style.css">


    <!-- Custom Fonts -->
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/>
    <link href="//fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" rel="stylesheet" type="text/css"/>
    <link href="//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css"/>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
    <script src="//oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="//oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- Gallery -->
    <link href="//cdnjs.cloudflare.com/ajax/libs/featherlight/1.3.5/featherlight.min.css" type="text/css" rel="stylesheet"/>

    <!-- Google Analytics -->
    


    <!-- favicon -->
    

</head>


<body>

    <!-- Menu -->
    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Configurable Title</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                
                    <li>
                        <a href="/">
                            
                                Home
                            
                        </a>
                    </li>
                
                    <li>
                        <a href="/archives">
                            
                                Archives
                            
                        </a>
                    </li>
                
                    <li>
                        <a href="/tags">
                            
                                Tags
                            
                        </a>
                    </li>
                
                    <li>
                        <a href="/categories">
                            
                                Categories
                            
                        </a>
                    </li>
                
                    <li>
                        <a target="_blank" rel="noopener" href="https://github.com/klugjo/hexo-theme-clean-blog">
                            
                                <i class="fa fa-github fa-stack-2x"></i>
                            
                        </a>
                    </li>
                
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>

    <!-- Main Content -->
    <!-- Page Header -->
<!-- Set your background image for this header in your post front-matter: cover -->

<header class="intro-header" style="background-image: url('/img/home-bg.jpg')">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <h1>Chapter 8장</h1>
                    
                    <span class="meta">
                        <!-- Date and Author -->
                        
                            Posted by Hanjeongin on
                        
                        
                            2022-04-11
                        
                    </span>
                </div>
            </div>
        </div>
    </div>
</header>

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

            <!-- Tags and categories -->
           
                <div class="col-lg-4 col-lg-offset-2 col-md-5 col-md-offset-1 post-tags">
                    
                        


<a href="/tags/Python/">#Python</a>


                    
                </div>
                <div class="col-lg-4 col-md-5 post-categories">
                    
                </div>
            

            <!-- Gallery -->
            

            <!-- Post Main Content -->
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <p>출처 : 혼자 공부하는 머신러닝+딥러닝</p>
<h1 id="순차-데이터와-순환-신경망"><a href="#순차-데이터와-순환-신경망" class="headerlink" title="순차 데이터와 순환 신경망"></a>순차 데이터와 순환 신경망</h1><ul>
<li>초급 레벨 : 기초통계 (t.test, 분산분석, 회귀분석 등)</li>
<li>중급 레벨 : 시계열 분석 &#x2F; 베이지안 &#x2F; 비모수검정</li>
<li>시계열 데이터 : 주식 &#x2F; 날씨 &#x2F; 매장 매출<ul>
<li>R로 공부를 해야함</li>
</ul>
</li>
</ul>
<h1 id="텍스트"><a href="#텍스트" class="headerlink" title="텍스트"></a>텍스트</h1><ul>
<li><p>텍스트 마이닝 (데이터 분석가)</p>
<ul>
<li>대표적으로 감정분석 (긍정 &#x2F; 부정 분류)</li>
<li>문자열 : 인코딩하는 방법론이 존재</li>
</ul>
</li>
<li><p>자연어 처리 (개발자에 해당)</p>
<ul>
<li>챗 봇 (툴은 다 존재함)</li>
<li>자동 번역</li>
</ul>
</li>
<li><p>기본 딥러닝 알고리즘 &#x2F; RNN &amp; LSTM</p>
<ul>
<li>현실에선 안씀</li>
</ul>
</li>
<li><p>자료</p>
<ul>
<li>딥러닝을 이용한 자연어 처리 입문 (텐서플로) : <a target="_blank" rel="noopener" href="https://wikidocs.net/book/2155">https://wikidocs.net/book/2155</a></li>
<li>Pytorch로 시작하는 딥러닝 입문 : <a target="_blank" rel="noopener" href="https://wikidocs.net/32471">https://wikidocs.net/32471</a></li>
</ul>
</li>
<li><p>분야 선정</p>
<ul>
<li>영상인식, 이미지 분류, 음성, 자연어</li>
</ul>
</li>
</ul>
<h1 id="순환-신경망"><a href="#순환-신경망" class="headerlink" title="순환 신경망"></a>순환 신경망</h1><ul>
<li><p>이미지는 픽셀값이 어느정도 고정되어 있음</p>
<ul>
<li>28 x 28로 정의 &#x2F; 모든 데이터는 28 x 28 맞출 수 있음</li>
</ul>
<ul>
<li>텍스트<ul>
<li>값이 고정이 불가함</li>
</ul>
</li>
</ul>
</li>
<li><p>교재 494페이지</p>
</li>
<li><p>i am a boy(1, 4, 3)</p>
</li>
<li><p>I am a hansome boy(1, 4, 1, 2</p>
</li>
</ul>
<h1 id="순환-신경망-IMDB-리뷰-분류"><a href="#순환-신경망-IMDB-리뷰-분류" class="headerlink" title="순환 신경망 IMDB 리뷰 분류"></a>순환 신경망 IMDB 리뷰 분류</h1><ul>
<li><p>주제 : 긍정리뷰 부정리뷰 분류</p>
</li>
<li><p>501p</p>
<ul>
<li>텍스트 자체가 신경망에 전달하지 않는다! (문자열 -&gt; 수식에 적용 X)</li>
<li>문자열을 수식으로 정하는 규칙이 매우 가변적임 (토큰화, Tokenizing)</li>
<li>He follows the cat. He loves the cat.</li>
<li>10 11      12  13   10 14    12  13</li>
<li>고양이를 따라간다. He follows the cat.</li>
<li>10       11        12 13      14  15</li>
</ul>
</li>
<li><p>RNN, LSTM 알고리즘</p>
<ul>
<li>영어권 사람들이 만듦</li>
<li>자연어처리와 관련된 많은 알고리즘</li>
<li>영어권 사람이 만듦</li>
</ul>
</li>
<li><p>한글 !&#x3D; 영어</p>
<ul>
<li>성과를 내려면 제품을 써야함 (&#x3D; 돈) (네이버)</li>
</ul>
</li>
</ul>
<h2 id="데이터-불러오기"><a href="#데이터-불러오기" class="headerlink" title="데이터 불러오기"></a>데이터 불러오기</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> imdb
<span class="token punctuation">(</span>train_input<span class="token punctuation">,</span> train_target<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>test_input<span class="token punctuation">,</span> test_target<span class="token punctuation">)</span> <span class="token operator">=</span> imdb<span class="token punctuation">.</span>load_data<span class="token punctuation">(</span>num_words <span class="token operator">=</span> <span class="token number">500</span><span class="token punctuation">)</span>
</code></pre>
<ul>
<li>데이터 크기 확인 (1차원 배열)</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>train_input<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> test_input<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre>
<pre><code>(25000,) (25000,)
</code></pre>
<ul>
<li>문장의 길이가 다 다름</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>len<span class="token punctuation">(</span>train_input<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>len<span class="token punctuation">(</span>train_input<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>len<span class="token punctuation">(</span>train_input<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<pre><code>218
189
141
</code></pre>
<ul>
<li>Raw 데이터 전처리 -&gt; 토큰화 작업이 끝난 상황 (문자열 -&gt; 숫자로 바뀜)</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>train_input<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<pre><code>[1, 14, 22, 16, 43, 2, 2, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 2, 112, 50, 2, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 2, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 2, 38, 76, 15, 13, 2, 4, 22, 17, 2, 17, 12, 16, 2, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 2, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 2, 36, 71, 43, 2, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]
</code></pre>
<ul>
<li>Target 데이터 출력<ul>
<li>0은 부정리뷰</li>
<li>1은 긍정리뷰</li>
</ul>
</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>train_target<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">20</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<pre><code>[1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1]
</code></pre>
<h1 id="데이터셋-분리"><a href="#데이터셋-분리" class="headerlink" title="데이터셋 분리"></a>데이터셋 분리</h1><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
train_input<span class="token punctuation">,</span> val_input<span class="token punctuation">,</span> train_target<span class="token punctuation">,</span> val_target <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>train_input<span class="token punctuation">,</span> train_target<span class="token punctuation">,</span> test_size <span class="token operator">=</span> <span class="token number">0.2</span><span class="token punctuation">,</span> random_state <span class="token operator">=</span> <span class="token number">42</span><span class="token punctuation">)</span>

train_input<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> val_input<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> train_target<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> val_target<span class="token punctuation">.</span>shape
</code></pre>
<pre><code>((20000,), (5000,), (20000,), (5000,))
</code></pre>
<h1 id="데이터-시각화"><a href="#데이터-시각화" class="headerlink" title="데이터 시각화"></a>데이터 시각화</h1><ul>
<li>각 리뷰의 평균단어의 갯수</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token comment" spellcheck="true"># temp_list = [len(x) for x in train_input]</span>
<span class="token comment" spellcheck="true"># print(temp_list)</span>
lengths <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>len<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> train_input<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>lengths<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>median<span class="token punctuation">(</span>lengths<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<pre><code>239.00925 178.0
</code></pre>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

fig<span class="token punctuation">,</span> ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token punctuation">)</span>

ax<span class="token punctuation">.</span>hist<span class="token punctuation">(</span>lengths<span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span><span class="token string">'length'</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'frequency'</span><span class="token punctuation">)</span>
fig<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<p><img src="/images/Chapter_9/output_19_0.png" alt="png"></p>
<ul>
<li>짧은 단어 100개만 사용</li>
<li>모든 길이를 100에 맞춰줌<ul>
<li>“패딩”</li>
</ul>
</li>
<li>데이터의 갯수는 20000, 전체 길이는 100으로 맞춤</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span>sequence <span class="token keyword">import</span> pad_sequences
train_seq <span class="token operator">=</span> pad_sequences<span class="token punctuation">(</span>train_input<span class="token punctuation">,</span> maxlen <span class="token operator">=</span> <span class="token number">100</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>train_seq<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre>
<pre><code>(20000, 100)
</code></pre>
<pre class=" language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>train_seq<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<pre><code>[  0   0   0   0   1   2 195  19  49   2   2 190   4   2 352   2 183  10
  10  13  82  79   4   2  36  71 269   8   2  25  19  49   7   4   2   2
   2   2   2  10  10  48  25  40   2  11   2   2  40   2   2   5   4   2
   2  95  14 238  56 129   2  10  10  21   2  94 364 352   2   2  11 190
  24 484   2   7  94 205 405  10  10  87   2  34  49   2   7   2   2   2
   2   2 290   2  46  48  64  18   4   2]
</code></pre>
<pre class=" language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>train_input<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>train_seq<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<pre><code>[6, 2, 46, 7, 14, 20, 10, 10, 470, 158]
[ 10   4  20   9   2 364 352   5  45   6   2   2  33 269   8   2 142   2
   5   2  17  73  17 204   5   2  19  55   2   2  92  66 104  14  20  93
  76   2 151  33   4  58  12 188   2 151  12 215  69 224 142  73 237   6
   2   7   2   2 188   2 103  14  31  10  10 451   7   2   5   2  80  91
   2  30   2  34  14  20 151  50  26 131  49   2  84  46  50  37  80  79
   6   2  46   7  14  20  10  10 470 158]
</code></pre>
<pre class=" language-python"><code class="language-python">val_seq <span class="token operator">=</span> pad_sequences<span class="token punctuation">(</span>val_input<span class="token punctuation">,</span> maxlen <span class="token operator">=</span> <span class="token number">100</span><span class="token punctuation">)</span>
</code></pre>
<h1 id="순환-신경망-만들기"><a href="#순환-신경망-만들기" class="headerlink" title="순환 신경망 만들기"></a>순환 신경망 만들기</h1><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> tensorflow <span class="token keyword">import</span> keras
model <span class="token operator">=</span> keras<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>SimpleRNN<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> input_shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">500</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">'sigmoid'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<ul>
<li>원핫 인코딩 적용</li>
</ul>
<pre class=" language-python"><code class="language-python">train_oh <span class="token operator">=</span> keras<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>to_categorical<span class="token punctuation">(</span>train_seq<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>train_oh<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre>
<pre><code>(20000, 100, 500)
</code></pre>
<pre class=" language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>train_oh<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">12</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<pre><code>[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
</code></pre>
<pre class=" language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>train_oh<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<pre><code>1.0
</code></pre>
<pre class=" language-python"><code class="language-python">val_oh <span class="token operator">=</span> keras<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>to_categorical<span class="token punctuation">(</span>val_seq<span class="token punctuation">)</span>
</code></pre>
<pre class=" language-python"><code class="language-python">model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<pre><code>Model: &quot;sequential&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn (SimpleRNN)      (None, 8)                 4072      
                                                                 
 dense (Dense)               (None, 1)                 9         
                                                                 
=================================================================
Total params: 4,081
Trainable params: 4,081
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<pre class=" language-python"><code class="language-python">rmsprop <span class="token operator">=</span> keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>RMSprop<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>optimizer<span class="token operator">=</span>rmsprop<span class="token punctuation">,</span> loss<span class="token operator">=</span><span class="token string">'binary_crossentropy'</span><span class="token punctuation">,</span> 
              metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

checkpoint_cb <span class="token operator">=</span> keras<span class="token punctuation">.</span>callbacks<span class="token punctuation">.</span>ModelCheckpoint<span class="token punctuation">(</span><span class="token string">'best-simplernn-model.h5'</span><span class="token punctuation">,</span> 
                                                save_best_only<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
early_stopping_cb <span class="token operator">=</span> keras<span class="token punctuation">.</span>callbacks<span class="token punctuation">.</span>EarlyStopping<span class="token punctuation">(</span>patience<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
                                                  restore_best_weights<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

history <span class="token operator">=</span> model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_oh<span class="token punctuation">,</span> train_target<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>
                    validation_data<span class="token operator">=</span><span class="token punctuation">(</span>val_oh<span class="token punctuation">,</span> val_target<span class="token punctuation">)</span><span class="token punctuation">,</span>
                    callbacks<span class="token operator">=</span><span class="token punctuation">[</span>checkpoint_cb<span class="token punctuation">,</span> early_stopping_cb<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<pre><code>Epoch 1/10
313/313 [==============================] - 43s 125ms/step - loss: 0.7005 - accuracy: 0.5166 - val_loss: 0.6957 - val_accuracy: 0.5234
Epoch 2/10
313/313 [==============================] - 39s 124ms/step - loss: 0.6874 - accuracy: 0.5462 - val_loss: 0.6830 - val_accuracy: 0.5638
Epoch 3/10
313/313 [==============================] - 39s 124ms/step - loss: 0.6706 - accuracy: 0.5918 - val_loss: 0.6643 - val_accuracy: 0.6044
Epoch 4/10
313/313 [==============================] - 39s 124ms/step - loss: 0.6491 - accuracy: 0.6342 - val_loss: 0.6417 - val_accuracy: 0.6374
Epoch 5/10
313/313 [==============================] - 40s 129ms/step - loss: 0.6220 - accuracy: 0.6725 - val_loss: 0.6162 - val_accuracy: 0.6708
Epoch 6/10
313/313 [==============================] - 39s 126ms/step - loss: 0.5925 - accuracy: 0.7084 - val_loss: 0.5883 - val_accuracy: 0.7078
Epoch 7/10
313/313 [==============================] - 40s 128ms/step - loss: 0.5661 - accuracy: 0.7348 - val_loss: 0.5662 - val_accuracy: 0.7290
Epoch 8/10
313/313 [==============================] - 39s 124ms/step - loss: 0.5466 - accuracy: 0.7486 - val_loss: 0.5514 - val_accuracy: 0.7376
Epoch 9/10
313/313 [==============================] - 40s 127ms/step - loss: 0.5307 - accuracy: 0.7603 - val_loss: 0.5381 - val_accuracy: 0.7442
Epoch 10/10
313/313 [==============================] - 40s 128ms/step - loss: 0.5159 - accuracy: 0.7687 - val_loss: 0.5218 - val_accuracy: 0.7580
</code></pre>
<ul>
<li>514p<ul>
<li>문제점 발생 : 토큰 1개를 500차원으로 늘림.. –&gt; 데이터 크기가 500배 커짐</li>
</ul>
</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> tensorflow <span class="token keyword">import</span> keras
model2 <span class="token operator">=</span> keras<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
model2<span class="token punctuation">.</span>add<span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span><span class="token number">500</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> input_length <span class="token operator">=</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model2<span class="token punctuation">.</span>add<span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>SimpleRNN<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model2<span class="token punctuation">.</span>add<span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">'sigmoid'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

model2<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<pre><code>Model: &quot;sequential&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 embedding (Embedding)       (None, 100, 16)           8000      
                                                                 
 simple_rnn (SimpleRNN)      (None, 8)                 200       
                                                                 
 dense (Dense)               (None, 1)                 9         
                                                                 
=================================================================
Total params: 8,209
Trainable params: 8,209
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<pre class=" language-python"><code class="language-python">rmsprop <span class="token operator">=</span> keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>RMSprop<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span>
model2<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>optimizer<span class="token operator">=</span>rmsprop<span class="token punctuation">,</span> loss<span class="token operator">=</span><span class="token string">'binary_crossentropy'</span><span class="token punctuation">,</span> 
              metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

checkpoint_cb <span class="token operator">=</span> keras<span class="token punctuation">.</span>callbacks<span class="token punctuation">.</span>ModelCheckpoint<span class="token punctuation">(</span><span class="token string">'best-simplernn-model.h5'</span><span class="token punctuation">,</span> 
                                                save_best_only<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
early_stopping_cb <span class="token operator">=</span> keras<span class="token punctuation">.</span>callbacks<span class="token punctuation">.</span>EarlyStopping<span class="token punctuation">(</span>patience<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
                                                  restore_best_weights<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

history <span class="token operator">=</span> model2<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_oh<span class="token punctuation">,</span> train_target<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>
                    validation_data<span class="token operator">=</span><span class="token punctuation">(</span>val_oh<span class="token punctuation">,</span> val_target<span class="token punctuation">)</span><span class="token punctuation">,</span>
                    callbacks<span class="token operator">=</span><span class="token punctuation">[</span>checkpoint_cb<span class="token punctuation">,</span> early_stopping_cb<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<pre><code>Epoch 1/10
WARNING:tensorflow:Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name=&#39;embedding_input&#39;), name=&#39;embedding_input&#39;, description=&quot;created by layer &#39;embedding_input&#39;&quot;), but it was called on an input with incompatible shape (None, 100, 500).



---------------------------------------------------------------------------

ValueError                                Traceback (most recent call last)

&lt;ipython-input-16-865acaa6cf17&gt; in &lt;module&gt;()
     10 history = model2.fit(train_oh, train_target, epochs=10, batch_size=64,
     11                     validation_data=(val_oh, val_target),
---&gt; 12                     callbacks=[checkpoint_cb, early_stopping_cb])


/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py in error_handler(*args, **kwargs)
     65     except Exception as e:  # pylint: disable=broad-except
     66       filtered_tb = _process_traceback_frames(e.__traceback__)
---&gt; 67       raise e.with_traceback(filtered_tb) from None
     68     finally:
     69       del filtered_tb


/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py in autograph_handler(*args, **kwargs)
   1145           except Exception as e:  # pylint:disable=broad-except
   1146             if hasattr(e, &quot;ag_error_metadata&quot;):
-&gt; 1147               raise e.ag_error_metadata.to_exception(e)
   1148             else:
   1149               raise


ValueError: in user code:

    File &quot;/usr/local/lib/python3.7/dist-packages/keras/engine/training.py&quot;, line 1021, in train_function  *
        return step_function(self, iterator)
    File &quot;/usr/local/lib/python3.7/dist-packages/keras/engine/training.py&quot;, line 1010, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File &quot;/usr/local/lib/python3.7/dist-packages/keras/engine/training.py&quot;, line 1000, in run_step  **
        outputs = model.train_step(data)
    File &quot;/usr/local/lib/python3.7/dist-packages/keras/engine/training.py&quot;, line 859, in train_step
        y_pred = self(x, training=True)
    File &quot;/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py&quot;, line 67, in error_handler
        raise e.with_traceback(filtered_tb) from None
    File &quot;/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py&quot;, line 214, in assert_input_compatibility
        raise ValueError(f&#39;Input &#123;input_index&#125; of layer &quot;&#123;layer_name&#125;&quot; &#39;

    ValueError: Exception encountered when calling layer &quot;sequential&quot; (type Sequential).
    
    Input 0 of layer &quot;simple_rnn&quot; is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 100, 500, 16)
    
    Call arguments received:
      • inputs=tf.Tensor(shape=(None, 100, 500), dtype=float32)
      • training=True
      • mask=None
</code></pre>
<h1 id="LSTM-신경망-훈련하기"><a href="#LSTM-신경망-훈련하기" class="headerlink" title="LSTM 신경망 훈련하기"></a>LSTM 신경망 훈련하기</h1><ul>
<li>RNN은 실모에서 안씀</li>
<li>나온 배경<ul>
<li>문장이 길면, 학습 능력이 떨어짐</li>
<li>Long Short-Term Memory</li>
</ul>
</li>
<li>단기 기억을 오래 기억하기 위해 고안됨</li>
</ul>
<h2 id="데이터-불러오기-1"><a href="#데이터-불러오기-1" class="headerlink" title="데이터 불러오기"></a>데이터 불러오기</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> imdb
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split

<span class="token punctuation">(</span>train_input<span class="token punctuation">,</span> train_target<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>test_input<span class="token punctuation">,</span> test_target<span class="token punctuation">)</span> <span class="token operator">=</span> imdb<span class="token punctuation">.</span>load_data<span class="token punctuation">(</span>
    num_words<span class="token operator">=</span><span class="token number">500</span><span class="token punctuation">)</span>

train_input<span class="token punctuation">,</span> val_input<span class="token punctuation">,</span> train_target<span class="token punctuation">,</span> val_target <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>
    train_input<span class="token punctuation">,</span> train_target<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span>
</code></pre>
<pre><code>Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz
17465344/17464789 [==============================] - 0s 0us/step
17473536/17464789 [==============================] - 0s 0us/step
</code></pre>
<h2 id="padding"><a href="#padding" class="headerlink" title="padding"></a>padding</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span>sequence <span class="token keyword">import</span> pad_sequences

train_seq <span class="token operator">=</span> pad_sequences<span class="token punctuation">(</span>train_input<span class="token punctuation">,</span> maxlen<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>
val_seq <span class="token operator">=</span> pad_sequences<span class="token punctuation">(</span>val_input<span class="token punctuation">,</span> maxlen<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>
</code></pre>
<h2 id="모형-만들기"><a href="#모형-만들기" class="headerlink" title="모형 만들기"></a>모형 만들기</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> tensorflow <span class="token keyword">import</span> keras
model <span class="token operator">=</span> keras<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span><span class="token number">500</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> input_length <span class="token operator">=</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># SimpleRNN</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">'sigmoid'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<pre><code>Model: &quot;sequential_2&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 embedding_2 (Embedding)     (None, 100, 16)           8000      
                                                                 
 lstm_2 (LSTM)               (None, 8)                 800       
                                                                 
 dense_2 (Dense)             (None, 1)                 9         
                                                                 
=================================================================
Total params: 8,809
Trainable params: 8,809
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<pre class=" language-python"><code class="language-python">rmsprop <span class="token operator">=</span> keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>RMSprop<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>optimizer<span class="token operator">=</span>rmsprop<span class="token punctuation">,</span> loss<span class="token operator">=</span><span class="token string">'binary_crossentropy'</span><span class="token punctuation">,</span> 
              metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

checkpoint_cb <span class="token operator">=</span> keras<span class="token punctuation">.</span>callbacks<span class="token punctuation">.</span>ModelCheckpoint<span class="token punctuation">(</span><span class="token string">'best-lstm-model.h5'</span><span class="token punctuation">,</span> 
                                                save_best_only<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
early_stopping_cb <span class="token operator">=</span> keras<span class="token punctuation">.</span>callbacks<span class="token punctuation">.</span>EarlyStopping<span class="token punctuation">(</span>patience<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
                                                  restore_best_weights<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

history <span class="token operator">=</span> model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_seq<span class="token punctuation">,</span> train_target<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>
                    validation_data<span class="token operator">=</span><span class="token punctuation">(</span>val_seq<span class="token punctuation">,</span> val_target<span class="token punctuation">)</span><span class="token punctuation">,</span>
                    callbacks<span class="token operator">=</span><span class="token punctuation">[</span>checkpoint_cb<span class="token punctuation">,</span> early_stopping_cb<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<pre><code>Epoch 1/10
313/313 [==============================] - 15s 41ms/step - loss: 0.5444 - accuracy: 0.7676 - val_loss: 0.5463 - val_accuracy: 0.7512
Epoch 2/10
313/313 [==============================] - 11s 37ms/step - loss: 0.5286 - accuracy: 0.7750 - val_loss: 0.5313 - val_accuracy: 0.7592
Epoch 3/10
313/313 [==============================] - 11s 37ms/step - loss: 0.5130 - accuracy: 0.7802 - val_loss: 0.5184 - val_accuracy: 0.7618
Epoch 4/10
313/313 [==============================] - 11s 37ms/step - loss: 0.4985 - accuracy: 0.7836 - val_loss: 0.5060 - val_accuracy: 0.7654
Epoch 5/10
313/313 [==============================] - 12s 37ms/step - loss: 0.4875 - accuracy: 0.7887 - val_loss: 0.4986 - val_accuracy: 0.7692
Epoch 6/10
313/313 [==============================] - 11s 37ms/step - loss: 0.4788 - accuracy: 0.7911 - val_loss: 0.4924 - val_accuracy: 0.7682
Epoch 7/10
313/313 [==============================] - 11s 37ms/step - loss: 0.4708 - accuracy: 0.7952 - val_loss: 0.4829 - val_accuracy: 0.7782
Epoch 8/10
313/313 [==============================] - 12s 37ms/step - loss: 0.4644 - accuracy: 0.7948 - val_loss: 0.4800 - val_accuracy: 0.7768
Epoch 9/10
313/313 [==============================] - 11s 36ms/step - loss: 0.4590 - accuracy: 0.7988 - val_loss: 0.4734 - val_accuracy: 0.7852
Epoch 10/10
313/313 [==============================] - 11s 37ms/step - loss: 0.4535 - accuracy: 0.8011 - val_loss: 0.4721 - val_accuracy: 0.7792
</code></pre>
<h2 id="손실-곡선-추가"><a href="#손실-곡선-추가" class="headerlink" title="손실 곡선 추가"></a>손실 곡선 추가</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'val_loss'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'epoch'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'loss'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'val'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<p><img src="/images/Chapter_9/output_46_0.png" alt="png"></p>
<h2 id="순환층에-드롭아웃-적용하기"><a href="#순환층에-드롭아웃-적용하기" class="headerlink" title="순환층에 드롭아웃 적용하기"></a>순환층에 드롭아웃 적용하기</h2><pre class=" language-python"><code class="language-python">model2 <span class="token operator">=</span> keras<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>

model2<span class="token punctuation">.</span>add<span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span><span class="token number">500</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> input_length<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 드롭아웃 추가</span>
model2<span class="token punctuation">.</span>add<span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> dropout<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model2<span class="token punctuation">.</span>add<span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'sigmoid'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

rmsprop <span class="token operator">=</span> keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>RMSprop<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span>
model2<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>optimizer<span class="token operator">=</span>rmsprop<span class="token punctuation">,</span> loss<span class="token operator">=</span><span class="token string">'binary_crossentropy'</span><span class="token punctuation">,</span> 
               metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

checkpoint_cb <span class="token operator">=</span> keras<span class="token punctuation">.</span>callbacks<span class="token punctuation">.</span>ModelCheckpoint<span class="token punctuation">(</span><span class="token string">'best-dropout-model.h5'</span><span class="token punctuation">,</span> 
                                                save_best_only<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
early_stopping_cb <span class="token operator">=</span> keras<span class="token punctuation">.</span>callbacks<span class="token punctuation">.</span>EarlyStopping<span class="token punctuation">(</span>patience<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
                                                  restore_best_weights<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># epcohs = 100</span>
history <span class="token operator">=</span> model2<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_seq<span class="token punctuation">,</span> train_target<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>
                     validation_data<span class="token operator">=</span><span class="token punctuation">(</span>val_seq<span class="token punctuation">,</span> val_target<span class="token punctuation">)</span><span class="token punctuation">,</span>
                     callbacks<span class="token operator">=</span><span class="token punctuation">[</span>checkpoint_cb<span class="token punctuation">,</span> early_stopping_cb<span class="token punctuation">]</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'val_loss'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'epoch'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'loss'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'val'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<pre><code>Epoch 1/10
313/313 [==============================] - 15s 41ms/step - loss: 0.6926 - accuracy: 0.5304 - val_loss: 0.6920 - val_accuracy: 0.5602
Epoch 2/10
313/313 [==============================] - 12s 39ms/step - loss: 0.6905 - accuracy: 0.5802 - val_loss: 0.6892 - val_accuracy: 0.6224
Epoch 3/10
313/313 [==============================] - 12s 38ms/step - loss: 0.6849 - accuracy: 0.6448 - val_loss: 0.6795 - val_accuracy: 0.6624
Epoch 4/10
313/313 [==============================] - 12s 37ms/step - loss: 0.6551 - accuracy: 0.6910 - val_loss: 0.6247 - val_accuracy: 0.7226
Epoch 5/10
313/313 [==============================] - 12s 38ms/step - loss: 0.6070 - accuracy: 0.7212 - val_loss: 0.5985 - val_accuracy: 0.7214
Epoch 6/10
313/313 [==============================] - 12s 39ms/step - loss: 0.5844 - accuracy: 0.7358 - val_loss: 0.5752 - val_accuracy: 0.7462
Epoch 7/10
313/313 [==============================] - 12s 39ms/step - loss: 0.5645 - accuracy: 0.7509 - val_loss: 0.5551 - val_accuracy: 0.7572
Epoch 8/10
313/313 [==============================] - 12s 39ms/step - loss: 0.5443 - accuracy: 0.7605 - val_loss: 0.5372 - val_accuracy: 0.7640
Epoch 9/10
313/313 [==============================] - 12s 38ms/step - loss: 0.5263 - accuracy: 0.7671 - val_loss: 0.5214 - val_accuracy: 0.7710
Epoch 10/10
313/313 [==============================] - 12s 38ms/step - loss: 0.5108 - accuracy: 0.7762 - val_loss: 0.5049 - val_accuracy: 0.7762
</code></pre>
<p><img src="/images/Chapter_9/output_48_1.png" alt="png"></p>


                
            </div>

            <!-- Comments -->
            
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    


                </div>
            
        </div>
    </div>
</article>

    <!-- Footer -->
    <hr />

<!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                    

                    

                    
                        <li>
                            <a href="https://github.com/klugjo/hexo-theme-clean-blog" target="_blank">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                    

                    

                    

                    
                </ul>
                <p class="copyright text-muted">&copy; 2022 SiriN<br></p>
                <p class="copyright text-muted">Original Theme <a target="_blank" href="http://startbootstrap.com/template-overviews/clean-blog/">Clean Blog</a> from <a href="http://startbootstrap.com/" target="_blank">Start Bootstrap</a></p>
                <p class="copyright text-muted">Adapted for <a target="_blank" href="https://hexo.io/">Hexo</a> by <a href="http://www.codeblocq.com/" target="_blank">Jonathan Klughertz</a></p>
            </div>
        </div>
    </div>
</footer>


    <!-- After footer scripts -->
    
<!-- jQuery -->
<script src="//code.jquery.com/jquery-2.1.4.min.js"></script>

<!-- Bootstrap -->
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"></script>

<!-- Gallery -->
<script src="//cdnjs.cloudflare.com/ajax/libs/featherlight/1.3.5/featherlight.min.js" type="text/javascript" charset="utf-8"></script>

<!-- Disqus Comments -->



</body>

</html>